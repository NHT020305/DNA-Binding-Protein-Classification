{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydropathy Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydropathy_index = {\n",
    "    'A': 1.8,   # Alanine\n",
    "    'C': 2.5,   # Cysteine\n",
    "    'D': -3.5,  # Aspartic Acid\n",
    "    'E': -3.5,  # Glutamic Acid\n",
    "    'F': 2.8,   # Phenylalanine\n",
    "    'G': -0.4,  # Glycine\n",
    "    'H': -0.2,  # Histidine\n",
    "    'I': 4.5,   # Isoleucine\n",
    "    'K': -3.9,  # Lysine\n",
    "    'L': 3.8,   # Leucine\n",
    "    'M': 1.9,   # Methionine\n",
    "    'N': -3.5,  # Asparagine\n",
    "    'P': -1.6,  # Proline\n",
    "    'Q': -3.5,  # Glutamine\n",
    "    'R': -4.5,  # Arginine\n",
    "    'S': -0.8,  # Serine\n",
    "    'T': -0.7,  # Threonine\n",
    "    'V': 4.2,   # Valine\n",
    "    'W': -0.9,  # Tryptophan\n",
    "    'Y': -1.3,  # Tyrosine\n",
    "}\n",
    "\n",
    "\n",
    "def hydropathy(protein_sequence, amino_acid_list):\n",
    "    hydropathy = 0\n",
    "    for amino_acid in protein_sequence:\n",
    "        if amino_acid not in amino_acid_list:\n",
    "            continue\n",
    "        hydropathy += hydropathy_index[amino_acid]\n",
    "    return hydropathy / len(protein_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net Charge Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pH = 7.0\n",
    "\n",
    "\n",
    "pKa_values = {\n",
    "        'K': 10.5,  # Lysine\n",
    "        'R': 12.5,  # Arginine\n",
    "        'H': 6.0,   # Histidine\n",
    "        'D': 3.9,   # Aspartic acid\n",
    "        'E': 4.2    # Glutamic acid\n",
    "    }\n",
    "\n",
    "\n",
    "def net_charge(protein_sequence, pH=selected_pH):\n",
    "    \n",
    "    charge = 0\n",
    "    \n",
    "    for amino_acid in protein_sequence:\n",
    "        if amino_acid in pKa_values:\n",
    "            if amino_acid in ['K', 'R', 'H']:  # Basic amino acids\n",
    "                if pH < pKa_values[amino_acid]:\n",
    "                    charge += 1  # Protonated form (positive charge)\n",
    "            elif amino_acid in ['D', 'E']:  # Acidic amino acids\n",
    "                if pH > pKa_values[amino_acid]:\n",
    "                    charge -= 1  # Deprotonated form (negative charge)\n",
    "    \n",
    "    return charge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amino Acids Distribution - Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amino_acids_distribution(data, binding_state, amino_acids_list):\n",
    "\n",
    "    column_list = amino_acids_list\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=4) \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    title = \"Distributions of Amino Acids\"\n",
    "\n",
    "    for i, column in enumerate(column_list):\n",
    "        used_data = data[data[\"Label\"] == binding_state][\"Frequency_\" + column]\n",
    "        counts, bins, _  = axes[i].hist(used_data, bins=20, color='blue', edgecolor='black') \n",
    "        axes[i].set_xlabel('Frequency')\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].set_title(column)\n",
    "\n",
    "    if binding_state:\n",
    "        plt.suptitle(title + \" in DNA-Binding Sequences\")\n",
    "    else:\n",
    "        plt.suptitle(title + \" in non DNA-Binding Sequences\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=1, hspace=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physiochemical Properties Distribution - Set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(data, feature, start=None, end=None):\n",
    "    \n",
    "    column_list = {1: \"DNA-binding\", 0: \"non DNA-binding\"}\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2) \n",
    "    axes  = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(column_list):\n",
    "        used_data = data[data[\"Label\"] == column][feature]\n",
    "        axes[i].boxplot(used_data, patch_artist=True, \n",
    "                        boxprops=dict(facecolor='lightblue', \n",
    "                                      edgecolor='black'))\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_title(column_list[column])\n",
    "        axes[i].set_ylim(start, end)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling - Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    normalized_data = min_max_scaler.fit_transform(data)\n",
    "    normalized_df = pd.DataFrame(normalized_data, columns=data.columns)\n",
    "    return normalized_df\n",
    "\n",
    "    \n",
    "def standardize(data):\n",
    "    scaler = StandardScaler()\n",
    "    standardized_data = scaler.fit_transform(data)\n",
    "    standardized_df = pd.DataFrame(standardized_data, columns=data.columns)\n",
    "    return standardized_df\n",
    "\n",
    "\n",
    "def robust_scaling(data):\n",
    "    scaler = RobustScaler()\n",
    "    robust_scaled_data = scaler.fit_transform(data)\n",
    "    robus_scaled_df = pd.DataFrame(robust_scaled_data, columns=data.columns)\n",
    "    return robus_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data(.fasta file) and convert to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids_list = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', \n",
    "                    'G', 'H', 'I', 'L', 'K', 'M', 'F', \n",
    "                    'P', 'S', 'T', 'W', 'Y', 'V']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Cleaning - Remove unnecessary amino acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_remove = ['X', 'U', \"O\", \"B\"]\n",
    "\n",
    "\n",
    "def remove_character(input_string, chars_to_remove):\n",
    "    for char in chars_to_remove:\n",
    "        input_string = input_string.replace(char, '')\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read .fasta file and convert to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_fasta_data(file_path, name):\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    records = SeqIO.parse(file_path, \"fasta\")\n",
    "\n",
    "    for record in records:\n",
    "        data.append([record.id, record.seq])\n",
    "    \n",
    "    data = pd.DataFrame(data, columns=[\"Label\", \"Sequence\"])\n",
    "    data['Label'] = data['Label'].apply(lambda x: x[-1])\n",
    "    data['Length'] = data['Sequence'].apply(len)\n",
    "\n",
    "    for amino_acid in amino_acids_list:\n",
    "        data['Frequency_' + amino_acid] = data['Sequence'].apply(lambda x: \n",
    "                                            x.count(amino_acid) / len(x))\n",
    "        \n",
    "    data['Sequence'] = data['Sequence'].apply(lambda x: \n",
    "                                remove_character(x, characters_to_remove))\n",
    "    \n",
    "    # Create new column: Hydropathy\n",
    "    data['Hydropathy'] = data['Sequence'].apply(lambda x: \n",
    "                        hydropathy(x, amino_acids_list))\n",
    "\n",
    "    # Create new column: Net_charge\n",
    "    data['Net_charge'] = data['Sequence'].apply(lambda x: net_charge(x))\n",
    "    \n",
    "\n",
    "\n",
    "    ########## ADDING PHYSIOCHEMICAL PROPERTIES ##########\n",
    "\n",
    "    # Define empty lists to store the computed values for each feature column\n",
    "    molecular_weights = []\n",
    "    instability_indexes = []\n",
    "    aromaticities = []\n",
    "    flexibilities = []\n",
    "    isoelectric_points = []\n",
    "    sec_structure_fractions = []\n",
    "\n",
    "    # Iterate through each protein sequence in the 'Sequence' column\n",
    "    for seq in data['Sequence']:\n",
    "        X = ProteinAnalysis(seq)\n",
    "    \n",
    "        # Append the computed values for each property to the respective list\n",
    "        molecular_weights.append(X.molecular_weight())\n",
    "        instability_indexes.append(X.instability_index())\n",
    "        aromaticities.append(X.aromaticity())\n",
    "        flexibilities.append(X.flexibility())  # Flexibility is a list\n",
    "        isoelectric_points.append(X.isoelectric_point())\n",
    "        sec_structure_fractions.append(X.secondary_structure_fraction())\n",
    "\n",
    "    # Add these lists as new columns to your DataFrame\n",
    "    data['Molecular Weight'] = molecular_weights\n",
    "    data['Instability Index'] = instability_indexes\n",
    "    data['Aromaticity'] = aromaticities\n",
    "    data['Flexibility(Mean)'] = [sum(flex)/len(flex) if len(flex) > 0 \n",
    "                                 else 0 for flex in flexibilities]\n",
    "    data['Isoelectric Point'] = isoelectric_points\n",
    "    data['Secondary Structure Fraction'] = [sum(fraction)/len(fraction) \n",
    "                                for fraction in sec_structure_fractions]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########## CONVERT TO CSV ##########\n",
    "    \n",
    "    data.to_csv(name, index=False)\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up dataframe for train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset(.fasta file) and convert to csv\n",
    "#dna_train = set_up_fasta_data(\"Data/Train.fasta\", \"Data/DNA_Train.csv\")\n",
    "#dna_test = set_up_fasta_data('Data/Test.fasta', \"Data/DNA_Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Already convert and from now will use the csv file to read data (more faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_train = pd.read_csv('Data/DNA_Train.csv')\n",
    "dna_test = pd.read_csv('Data/DNA_Test.csv')\n",
    "\n",
    "\n",
    "# Convert 'Label' to a categorical variable\n",
    "dna_train['Label'] = pd.Categorical(dna_train['Label'])\n",
    "dna_test['Label'] = pd.Categorical(dna_test['Label'])\n",
    "\n",
    "\n",
    "# Remove missing values from the training data\n",
    "dna_train = dna_train.dropna()\n",
    "\n",
    "\n",
    "# Ensure the labels are treated as binary\n",
    "dna_train['Label'] = dna_train['Label'].cat.codes  # 0 for \"0\" and 1 for \"1\"\n",
    "dna_test['Label'] = dna_test['Label'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Length - Amino Acids - K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(dna_train, \"Length\", 0, 5000)\n",
    "\n",
    "#plot_amino_acids_distribution(dna_train, 1, amino_acids_list)\n",
    "\n",
    "#plot_amino_acids_distribution(dna_train, 0, amino_acids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Physiochemical Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(dna_train, 'Hydropathy', -3, 3)\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Net_charge', -500, 500)\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Molecular Weight')\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Instability Index', -50, 180)\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Aromaticity', -0.05, 0.4)\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Flexibility(Mean)', 0.93, 1.06)\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Isoelectric Point')\n",
    "\n",
    "plot_feature_distribution(dna_train, 'Secondary Structure Fraction', 0.1, 0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up features, trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ # 0\n",
    "            'Length',\n",
    "            \n",
    "            # 1 - 20\n",
    "            'Frequency_A', 'Frequency_R', 'Frequency_N', 'Frequency_D', \n",
    "            'Frequency_C', 'Frequency_E', 'Frequency_Q', 'Frequency_G', \n",
    "            'Frequency_H', 'Frequency_I', 'Frequency_L', 'Frequency_K', \n",
    "            'Frequency_M', 'Frequency_F', 'Frequency_P', 'Frequency_S', \n",
    "            'Frequency_T', 'Frequency_W', 'Frequency_Y', 'Frequency_V',\n",
    "            \n",
    "            # 21 - 22\n",
    "            'Hydropathy', \n",
    "            'Net_charge',\n",
    "\n",
    "            # 23 - 24\n",
    "            'Molecular Weight',\n",
    "            'Instability Index',\n",
    "            \n",
    "            # 25 - 26\n",
    "            'Aromaticity',\n",
    "            'Flexibility(Mean)',\n",
    "            \n",
    "            # 27 - 28\n",
    "            'Isoelectric Point',\n",
    "            'Secondary Structure Fraction' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_find = columns[21:]\n",
    "\n",
    "indices = [dna_train.columns.get_loc(col) for col \n",
    "           in columns_to_find if col in dna_train.columns]\n",
    "\n",
    "features = indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dna_train.iloc[:, features]\n",
    "test_x = dna_test.iloc[:, features]\n",
    "train_y = dna_train.iloc[:, 0]\n",
    "test_y = dna_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, matthews_corrcoef, precision_recall_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics - Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_confusion_matrix(test_set, predicted_set, name):\n",
    "    \n",
    "    conf_matrix = confusion_matrix(test_set, predicted_set)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non DNA-Binding', 'DNA-Binding'], \n",
    "            yticklabels=['Non DNA-Binding', 'DNA-Binding'])\n",
    "    \n",
    "    plt.title('Confusion Matrix of ' + name)\n",
    "    \n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_performance_metrics(test, pred):\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    precision = precision_score(test, pred)\n",
    "    recall = recall_score(test, pred)\n",
    "    f1 = f1_score(test, pred)\n",
    "    mcc = matthews_corrcoef(test, pred)\n",
    "    roc_auc = roc_auc_score(test, pred)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(test, pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificitY\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"Accuracy\": round(accuracy, 2),\n",
    "        \"Precision\": round(precision, 2),\n",
    "        \"Recall\": round(recall, 2),\n",
    "        \"F1 Score\": round(f1, 2),\n",
    "        \"Specificity\": round(specificity, 2),\n",
    "        \"MCC\": round(mcc, 2)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC - ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_probs, name):\n",
    "    \n",
    "    # Step 5: Compute ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Step 6: Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='b', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('RECEIVER OPERATING CHARACTERISTIC of '+ name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC - PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_pr(y_test, y_probs, name):\n",
    "    # Step 1: Compute Precision-Recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "    \n",
    "    # Step 2: Compute AUC-PR\n",
    "    auc_pr = auc(recall, precision)\n",
    "    \n",
    "    # Step 3: Plot the Precision-Recall curve\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, color='b', lw=2, label=f'PR curve (AUC = {auc_pr:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('PRECISION-RECALL CURVE of ' + name)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant (intercept) to the model\n",
    "train_x = sm.add_constant(train_x)\n",
    "test_x = sm.add_constant(test_x)\n",
    "\n",
    "\n",
    "# Fit logistic regression model\n",
    "logit_model = sm.Logit(train_y, train_x)\n",
    "result = logit_model.fit()\n",
    "\n",
    "\n",
    "# Print summary (which includes p-values)\n",
    "print(result.summary())\n",
    "\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "predicted_probs = result.predict(test_x)\n",
    "\n",
    "\n",
    "# Convert probabilities to class labels (0 or 1) using 0.5 threshold\n",
    "predicted_classes = np.where(predicted_probs > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = sketch_confusion_matrix(test_y, predicted_classes, \n",
    "                        \"Logistic Regression - Physiochemical Properties\")\n",
    " \n",
    "\n",
    "# Performance metrics\n",
    "print()\n",
    "print(\"PERFORMANCE METRICS OF LOGISTIC REGRESSION:\")\n",
    "print()\n",
    "print(get_performance_metrics(test_y, predicted_classes))\n",
    "print()\n",
    "print(classification_report(test_y, predicted_classes))\n",
    "plot_roc_curve(test_y, predicted_probs, \"LOGISTIC REGRESSION\")\n",
    "plot_auc_pr(test_y, predicted_probs, \"LOGISTIC REGRESSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K NEAREST NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "train_x_scaled = standardize(train_x)\n",
    "test_x_scaled = standardize(test_x)\n",
    "\n",
    "\n",
    "# Create the k-NN classifier with value k\n",
    "k = 181\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_pred = knn.fit(train_x_scaled, train_y)\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "knn_pred = knn.predict(test_x_scaled)\n",
    "knn_scores = knn.predict_proba(test_x_scaled)[:,1]\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = sketch_confusion_matrix(test_y, knn_pred, \"KNN with k = \" \n",
    "                                + str(k) + \" - Physiochemical Properties\")\n",
    "\n",
    "\n",
    "# Performance metrics\n",
    "print(\"PERFORMANCE METRICS OF KNN MODEL WITH K = \" + str(k) + \":\" )\n",
    "print()\n",
    "print(get_performance_metrics(test_y, knn_pred))\n",
    "print()\n",
    "print(classification_report(test_y, knn_pred)) \n",
    "plot_roc_curve(test_y, knn_scores, \"KNN with k = \" + str(k))\n",
    "plot_auc_pr(test_y, knn_scores, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Decision Tree\n",
    "dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=7,\n",
    "                                    min_samples_split=2, random_state=42)\n",
    "dt_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# Predict\n",
    "dt_pred = dt_model.predict(test_x)\n",
    "dt_scores = dt_model.predict_proba(test_x)[:,1]\n",
    "\n",
    "\n",
    "# Visualize the Decision Tree\n",
    "# plt.figure(figsize=(20,10)) \n",
    "# plot_tree(dt_model, filled=True, feature_names=train_x.columns, \n",
    "#           class_names=[\"0\", \"1\"], rounded=True, fontsize=14)\n",
    "# plt.title(\"Decision Tree - Physiochemical Properties\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = sketch_confusion_matrix(test_y, dt_pred, \n",
    "      \"Decision Tree - Physiochemical Properties\")\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "print(\"PERFORMANCE METRICS OF DECISION TREE:\")\n",
    "print()\n",
    "print(get_performance_metrics(test_y, dt_pred))\n",
    "print()\n",
    "print(classification_report(test_y, dt_pred)) \n",
    "plot_roc_curve(test_y, dt_scores, \"DECISION TREE\")\n",
    "plot_auc_pr(test_y, dt_scores, \"DECISION TREE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# Predict\n",
    "nb_pred = nb_model.predict(test_x)\n",
    "nb_scores = nb_model.predict_proba(test_x)[:,1]\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = sketch_confusion_matrix(test_y, nb_pred, \n",
    "      \"Naive Bayes - Physiochemical Properties\")\n",
    "\n",
    "\n",
    "# Performance metrics\n",
    "print(\"PERFORMANCE METRICS OF NAIVE BAYES:\")\n",
    "print()\n",
    "print(get_performance_metrics(test_y, nb_pred))\n",
    "print()\n",
    "print(classification_report(test_y, nb_pred)) \n",
    "plot_roc_curve(test_y, nb_scores, \"NAIVE BAYES\")\n",
    "plot_auc_pr(test_y, nb_scores, \"NAIVE BAYES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# Performance metrics\n",
    "rf_pred = rf_model.predict(test_x)\n",
    "rf_scores = rf_model.predict_proba(test_x)[:,1]\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = sketch_confusion_matrix(test_y, rf_pred, \n",
    "      \"Random Forest - Physiochemical Properties\")\n",
    "\n",
    "\n",
    "# Performance metrics\n",
    "print(\"PERFORMANCE METRICS OF RANDOM FOREST:\")\n",
    "print()\n",
    "print(get_performance_metrics(test_y, rf_pred))\n",
    "print()\n",
    "print(classification_report(test_y, rf_pred)) \n",
    "plot_roc_curve(test_y, rf_scores, \"RANDOM FOREST\")\n",
    "plot_auc_pr(test_y, rf_scores, \"RANDOM FOREST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "train_x_scaled = robust_scaling(train_x)\n",
    "test_x_scaled = robust_scaling(test_x)\n",
    "\n",
    "\n",
    "# Initialize and fit SVM\n",
    "svm_model = SVC(probability=True)\n",
    "#svm_model.fit(train_x_scaled, train_y)\n",
    "\n",
    "\n",
    "# Predict\n",
    "#svm_pred = svm_model.predict(test_x_scaled)\n",
    "#svm_scores = svm_model.predict_proba(test_x_scaled)[:,1]\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "#conf_matrix = sketch_confusion_matrix(test_y, svm_pred, \n",
    "      #\"Support Vector Machine - Physiochemical Properties\")\n",
    "\n",
    "\n",
    "# Performance metrics\n",
    "print(\"PERFORMANCE METRICS OF SUPPORT VECTOR MACHINE:\")\n",
    "print()\n",
    "#print(get_performance_metrics(test_y, svm_pred))\n",
    "print()\n",
    "#print(classification_report(test_y, svm_pred))\n",
    "#plot_roc_curve(test_y, svm_scores, \"SUPPORT VECTOR MACHINE\") \n",
    "#plot_auc_pr(test_y, svm_scores, \"SUPPORT VECTOR MACHINE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
